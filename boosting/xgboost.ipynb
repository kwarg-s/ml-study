{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost = Extreme Gradient Boosting 모델\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost에서 개선된 점\n",
    "- 자체적으로 결측치를 처리한다\n",
    "- 속도를 향상한다. \n",
    "  - 근사 분할 탐색 알고리즘: 평범한 결정 트리는 그리디 알고리즘을 사용하지만, xgboost에서는 데이터를 나누는 퍼센트인 분위수 (퀀타일)을 사용해서 후보 분할을 제안한다. \n",
    "  - 희소성 고려 분할 탐색\n",
    "  - 병렬 컴퓨팅: 부스팅은 이전 트리의 결과에 의존하기 때문에 병렬 컴퓨팅이 어렵다. 병렬 컴퓨팅이란 여러 개의 계산 유닛이 동시에 동일한 작업을 하는 것인데 xgboost는 데이터를 블록이라는 단위로 정렬하고 압축하여 여러 대의 머신이나 외부 메모리에 분산시킨다. \n",
    "  - 캐시 고려 접근: 캐시를 고려한 프리페칭을 사용한다. \n",
    "  - 블록 압축, 블록 샤딩\n",
    "- 정확도를 향상한다.\n",
    "  - 자체적으로 regularization 추가: 분산을 줄이고 과대적합을 방지한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 목록\n",
    "| 이름              | 설명                                                                            | 기본값 |\n",
    "|-------------------|---------------------------------------------------------------------------------|--------|\n",
    "| n_estimators      | 앙상블의 트리 개수                                                              | 100    |\n",
    "| learning_rate     | 부스팅의 각 단계에서 트리의 기여도를 조절                                       | 0.3    |\n",
    "| max_depth         | 개별 트리의 최대 성장 가능한 깊이. 제한하면 과대적합 방지                       | 6      |\n",
    "| gamma             | 라그랑주 승수. 노드 분할을 위한 최소 손실 감소를 지정한다. 늘리면 과대적합 방지 | 0      |\n",
    "| min_child_weight  | 노드를 분할하기 위해 필요한 최소 가중치 합. 늘리면 과대적합 방지                | 1      |\n",
    "| subsample         | 부스팅의 각 단계에서 사용되는 훈련 샘플의 비율 제한. 줄이면 과대적합 방지       | 1      |\n",
    "| colsample_bytree  | 부스팅의 각 단계에서 사용되는 feature의 비율을 제한. 줄이면 과대적합 방지       | 1      |\n",
    "| colsample_bylevel | 트리의 깊이마다 사용되는 feature의 비율 제한. 줄이면 과대적합 방지              | 1      |\n",
    "| colsample_bynode  | 노드를 분할할 때마다 사용되는 feature의 비율 제한. 줄이면 과대적합 방지         | 1      |\n",
    "| scale_pos_weight  | 언밸런스한 데이터에 대해 양성샘플과 음성샘플의 가중치 비율을 설정할 수 있다     | 1      |\n",
    "| lambda            | 가중치 l2 규제를 통해 과대적합 방지                                             | 1      |\n",
    "| alpha             | 가중치 l1 규제를 통해 과대적합 방지                                             | 0      |\n",
    "| missing           | 누락된 값을 이 수치로 대체함.                                                   | None   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 경고 끄기\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import xgboost as xgb\n",
    "xgb.set_config(verbosity=0)\n",
    "\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# cross_val_score를 임포트합니다.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# numpy를 임포트합니다.\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/heart_disease.csv')\n",
    "\n",
    "# 데이터를 X와 y로 나눕니다.\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: [0.84 0.85 0.82 0.8  0.77]\n",
      "정확도 평균: 0.81\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(booster='gbtree', objective='binary:logistic')\n",
    "\n",
    "# 교차 검증 점수를 구합니다.\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "# 정확도를 출력합니다.\n",
    "print('정확도:', np.round(scores, 2))\n",
    "\n",
    "# 정확도 평균을 출력합니다.\n",
    "print('정확도 평균: %0.2f' % (scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV를 임포트합니다.\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "\n",
    "def grid_search(params, random=False): \n",
    "\n",
    "    xgb = XGBClassifier(booster='gbtree', objective='binary:logistic', \n",
    "                        random_state=2, verbosity=0, use_label_encoder=False)\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "    \n",
    "    if random:\n",
    "        grid = RandomizedSearchCV(xgb, params, cv=kfold, n_iter=20, \n",
    "                                  n_jobs=-1, random_state=2)\n",
    "    else:\n",
    "        grid = GridSearchCV(xgb, params, cv=kfold, n_jobs=-1)\n",
    "    \n",
    "    # X와 y에서 하이퍼파라미터 튜닝을 수행합니다.\n",
    "    grid.fit(X, y)\n",
    "\n",
    "    # 최상의 매개변수를 추출합니다.\n",
    "    best_params = grid.best_params_\n",
    "\n",
    "    # 최상의 매개변수를 출력합니다.\n",
    "    print(\"최상의 매개변수:\", best_params)\n",
    "    \n",
    "    # 최상의 점수를 추출합니다.\n",
    "    best_score = grid.best_score_\n",
    "\n",
    "    # 최상의 점수를 출력합니다.\n",
    "    print(\"최상의 점수: {:.5f}\".format(best_score))\n",
    "\n",
    "grid_search(params={'n_estimators':[100, 200, 400, 800]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.15789\n",
      "[1]\tvalidation_0-error:0.10526\n",
      "[2]\tvalidation_0-error:0.11842\n",
      "[3]\tvalidation_0-error:0.13158\n",
      "[4]\tvalidation_0-error:0.11842\n",
      "[5]\tvalidation_0-error:0.14474\n",
      "[6]\tvalidation_0-error:0.14474\n",
      "[7]\tvalidation_0-error:0.14474\n",
      "[8]\tvalidation_0-error:0.14474\n",
      "[9]\tvalidation_0-error:0.14474\n",
      "[10]\tvalidation_0-error:0.14474\n",
      "[11]\tvalidation_0-error:0.15789\n",
      "정확도: 89.47%\n"
     ]
    }
   ],
   "source": [
    "# train_test_split 함수를 임포트합니다.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 세트와 테스트 세트로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)\n",
    "\n",
    "model = XGBClassifier(booster='gbtree', objective='binary:logistic')\n",
    "eval_set = [(X_test, y_test)]\n",
    "eval_metric=\"error\"\n",
    "model.fit(X_train, y_train, eval_metric=eval_metric, eval_set=eval_set, \n",
    "          early_stopping_rounds=10, verbose=True)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"정확도: %.2f%%\" % (accuracy * 100.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d97dfac72b5344da9592506e8ae21cbbdfd9437ca0e05329aac99300b906c4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
