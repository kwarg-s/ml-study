{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQ2KGyLJ99Yi"
   },
   "source": [
    "# 랭체인 사전 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkPbwp6-ploX"
   },
   "outputs": [],
   "source": [
    "# 패키지 설치\n",
    "!pip install langchain==0.0.181\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Gf8Rfw2MiG_"
   },
   "outputs": [],
   "source": [
    "# 환경변수 준비\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<OpenAI_API의 API키>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x-T5eel0PlD3"
   },
   "outputs": [],
   "source": [
    "# 패키지 설치\n",
    "!pip install faiss-gpu\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPJ2lQW0-J3a"
   },
   "source": [
    "# 제네릭 체인\n",
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJAvf0Xsc8RE"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "# 템플릿 생성\n",
    "template = \"\"\"Q: {question}\n",
    "A:\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "# LLMChain 생성\n",
    "llm_chain = LLMChain(\n",
    "    llm=OpenAI(temperature=0),\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# LLMChain 실행\n",
    "question = \"기타를 잘 치는 방법은?\"\n",
    "print(llm_chain.predict(question=question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LXUV97u7c8TS"
   },
   "outputs": [],
   "source": [
    "# 템플릿 생성\n",
    "template = \"\"\"{subject}를 주제로 {target}를 작성해 주세요.\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"subject\", \"target\"]\n",
    ")\n",
    "\n",
    "# LLMChain 생성\n",
    "llm_chain = LLMChain(\n",
    "    llm=OpenAI(temperature=0),\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# LLMChain 실행\n",
    "print(llm_chain.predict(subject=\"고양이\", target=\"시\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0VWNg2mg9yc"
   },
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WaUJA0doc8VN"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "# 템플릿 준비\n",
    "template = \"\"\"당신은 극작가입니다. 연극 제목이 주어졌을 때, 그 줄거리를 작성하는 것이 당신의 임무입니다.\n",
    "\n",
    "제목:{title}\n",
    "시놉시스:\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿 준비\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"title\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "# LLMChain 준비\n",
    "chain1 = LLMChain(\n",
    "    llm=OpenAI(temperature=0),\n",
    "    prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABBLfWqZi0ub"
   },
   "outputs": [],
   "source": [
    "# 템플릿 생성\n",
    "template = \"\"\"당신은 연극 평론가입니다. 연극의 시놉시스가 주어지면 그 리뷰를 작성하는 것이 당신의 임무입니다.\n",
    "\n",
    "시놉시스:\n",
    "{synopsis}\n",
    "리뷰:\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿 준비\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"synopsis\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "# LLMChain 준비\n",
    "chain2 = LLMChain(\n",
    "    llm=OpenAI(temperature=0),\n",
    "    prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "auWI2Hj5i0y0"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "# SimpleSequentialChain으로 두 개의 체인을 연결\n",
    "overall_chain = SimpleSequentialChain(\n",
    "    chains=[chain1, chain2],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgRhwV6Qc8XT"
   },
   "outputs": [],
   "source": [
    "# SimpleSequentialChain 실행\n",
    "print(overall_chain.run(\"서울 랩소디\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgZIDfSgkh0c"
   },
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stYxOZKglZ7U"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "# 템플릿 생성\n",
    "template = \"\"\"당신은 극작가입니다. 극의 제목과 시대적 배경이 주어졌을 때, 그 줄거리를 작성하는 것이 당신의 임무입니다.\n",
    "\n",
    "제목:{title}\n",
    "시대:{era}\n",
    "시놉시스:\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"title\", \"era\"], \n",
    "    template=template\n",
    ")\n",
    "\n",
    "# LLMChain 생성\n",
    "chain1 = LLMChain(\n",
    "    llm=OpenAI(temperature=0),\n",
    "    prompt=prompt, \n",
    "    output_key=\"synopsis\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-yRMJO4DlaAS"
   },
   "outputs": [],
   "source": [
    "# 템플릿 생성\n",
    "template = \"\"\"당신은 연극 평론가입니다. 연극의 시놉시스가 주어지면 그 리뷰를 작성하는 것이 당신의 임무입니다.\n",
    "\n",
    "시놉시스:\n",
    "{synopsis}\n",
    "리뷰:\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"synopsis\"], \n",
    "    template=template\n",
    ")\n",
    "\n",
    "# LLMChain 준비\n",
    "chain2 = LLMChain(\n",
    "    llm=OpenAI(temperature=0),\n",
    "    prompt=prompt, \n",
    "    output_key=\"review\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-q1vRpSwmXE5"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "# SequentialChain으로 두 개의 체인을 연결\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain1, chain2],\n",
    "    input_variables=[\"title\", \"era\"],\n",
    "    output_variables=[\"synopsis\", \"review\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORP8rTN1mXkY"
   },
   "outputs": [],
   "source": [
    "# SequentialChain 실행\n",
    "print(overall_chain({\"title\":\"서울 랩소디\", \"era\": \"100년 후의 미래\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loLMwgdwdzfW"
   },
   "source": [
    "# 인덱스 체인\n",
    "## RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKAYubWmn-2M"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# 문서 불러오기(현재 폴더에 문서를 넣어둡니다)\n",
    "with open(\"akazukin_all.txt\") as f:\n",
    "    test_all = f.read()\n",
    "\n",
    "# 청크 분할\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\\n\", # 구분 기호\n",
    "    chunk_size=300, # 청크의 최대 문자 수\n",
    "    chunk_overlap=20 # 겹치는 최대 문자 수\n",
    ")\n",
    "texts = text_splitter.split_text(test_all)\n",
    "\n",
    "# 확인\n",
    "print(len(texts))\n",
    "for text in texts:\n",
    "    print(text[:10], \":\", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R7HiXice6SO-"
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "\n",
    "# 벡터 데이터베이스 생성\n",
    "docsearch = FAISS.from_texts(\n",
    "    texts=texts, # 청크 배열\n",
    "    embedding=OpenAIEmbeddings() # 임베딩\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CgBJjVjLDpFL"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# 질의응답 체인 생성\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(temperature=0), # LLM\n",
    "    chain_type=\"stuff\", # 체인 종류\n",
    "    retriever=docsearch.as_retriever(), # 리트리버\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFHGEQsQ7u_X"
   },
   "outputs": [],
   "source": [
    "# 질의응답 체인 실행\n",
    "print(qa_chain.run(\"미코의 소꿉친구 이름은?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPVR_OB_E0vp"
   },
   "source": [
    "## RetrievalQAWithSourcesChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TRE7yxXiFV-f"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# 문서 로드\n",
    "with open(\"akazukin_all.txt\") as f:\n",
    "    test_all = f.read()\n",
    "\n",
    "# 청크 분할\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\\n\", # 구분 기호\n",
    "    chunk_size=300, # 청크의 최대 문자 수\n",
    "    chunk_overlap=20, # 최대 오버랩 문자 수\n",
    ")\n",
    "texts = text_splitter.split_text(test_all)\n",
    "\n",
    "# 확인\n",
    "print(len(texts))\n",
    "for text in texts:\n",
    "    print(text[:10], \":\", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6fmoKptjFWO5"
   },
   "outputs": [],
   "source": [
    "# 메타데이터 준비\n",
    "metadatas=[\n",
    "    {\"source\": \"1장\"},\n",
    "    {\"source\": \"2장\"},\n",
    "    {\"source\": \"3장\"},\n",
    "    {\"source\": \"4장\"},\n",
    "    {\"source\": \"5~6장\"},\n",
    "    {\"source\": \"7장\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLXqPsw8FWSx"
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "\n",
    "# 벡터 데이터베이스 생성\n",
    "docsearch = FAISS.from_texts(\n",
    "    texts=texts, # 청크 배열\n",
    "    embedding=OpenAIEmbeddings(), # 임베딩\n",
    "    metadatas=metadatas # 메타데이터\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tg2Srbl4Hc8T"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "# 소스가 있는 질의응답 체인 생성\n",
    "qa_chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=OpenAI(temperature=0),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=docsearch.as_retriever(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5gIi6UYICIQ"
   },
   "outputs": [],
   "source": [
    "# 소스가 있는 질의응답 체인 실행\n",
    "print(qa({\"question\": \"미코의 소꿉친구 이름은?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CH-1KP49I3nj"
   },
   "source": [
    "# SummarizeChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BdvQsygSI-dC"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# 문서 로드\n",
    "with open(\"akazukin_all.txt\") as f:\n",
    "    test_all = f.read()\n",
    "\n",
    "# 청크 분할\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\\n\", # 구분 기호\n",
    "    chunk_size=300, # 청크의 최대 문자 수\n",
    "    chunk_overlap=20, # 최대 오버랩 문자 수\n",
    ")\n",
    "texts = text_splitter.split_text(test_all)\n",
    "\n",
    "# 확인\n",
    "print(len(texts))\n",
    "for text in texts:\n",
    "    print(text[:10], \":\", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mBalbaBGKvnl"
   },
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "# 청크 배열을 문서 배열로 변환\n",
    "docs = [Document(page_content=t) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZV6BNPLJHvk"
   },
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# 요약 체인 생성\n",
    "chain = load_summarize_chain(\n",
    "    llm=OpenAI(temperature=0),\n",
    "    chain_type=\"map_reduce\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vode4HALJkOR"
   },
   "outputs": [],
   "source": [
    "# 요약 체인 실행\n",
    "chain.run(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvCpbUff0eaF"
   },
   "source": [
    "\n",
    "# 유틸리티 체인\n",
    "## PALChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ii49WzoY3nQc"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import PALChain\n",
    "from langchain import OpenAI\n",
    "\n",
    "# PALChain 생성\n",
    "pal_chain = PALChain.from_math_prompt(\n",
    "    llm=OpenAI(), \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# PALChain 실행\n",
    "question = \"제인은 앨리스가 키우는 반려동물의 3배가 되는 반려동물을 키우고 있다. 앨리스가 2마리의 반려동물을 키우고 있다면 두 사람이 키우고 있는 반려동물의 총 마리 수는?\"\n",
    "print(pal_chain.run(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1Pjn2AZw4SZ"
   },
   "source": [
    "## OpenAIModerationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ARMSaNZ_0eml"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import OpenAIModerationChain\n",
    "\n",
    "# OpenAIModerationChain 준비\n",
    "chain = OpenAIModerationChain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tadNzoXZ2JIY"
   },
   "outputs": [],
   "source": [
    "# 문제없는 발언\n",
    "chain.run(\"This is OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jyxErTWN2KfV"
   },
   "outputs": [],
   "source": [
    "# 문제 발언\n",
    "chain.run(\"I'll kill you!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vx5xv5Z72MKZ"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import OpenAIModerationChain\n",
    "\n",
    "# OpenAIModerationChain 준비\n",
    "chain = OpenAIModerationChain(error=True)\n",
    "\n",
    "try:\n",
    "    # 문제 있는 발언\n",
    "    chain.run(\"I'll kill you!\")\n",
    "except ValueError as e:\n",
    "    print(\"문제 발언입니다!\")\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMcH9zwjBQtOzkuFO3pXSAH",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
