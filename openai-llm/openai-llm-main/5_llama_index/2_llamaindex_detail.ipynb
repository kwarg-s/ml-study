{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qf_XcjXD89hw"
   },
   "source": [
    "# 라마인덱스 사전 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkPbwp6-ploX"
   },
   "outputs": [],
   "source": [
    "# 패키지 설치\n",
    "!pip install llama-index==0.6.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Gf8Rfw2MiG_"
   },
   "outputs": [],
   "source": [
    "# 환경변수 준비\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<OpenAI_API의_API_키>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9Nyr59eqRUh"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# 로그 레벨 설정\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKqtnf0Gf24g"
   },
   "source": [
    "# 문서 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WsBr4NJx50By"
   },
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "# 문서 로드\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "print(\"documents :\", documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fVtBdcVHQHub"
   },
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "\n",
    "# 수동으로 문서 생성\n",
    "texts = [\"text1\", \"text2\", \"text3\"]\n",
    "documents = [Document(t) for t in texts]\n",
    "print(\"documents :\", documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NueCxFlnQHwf"
   },
   "outputs": [],
   "source": [
    "from llama_index import GPTVectorStoreIndex\n",
    "\n",
    "# 인덱스 생성\n",
    "index = GPTVectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mPvIHzB-QHyl"
   },
   "outputs": [],
   "source": [
    "from llama_index import GPTVectorStoreIndex\n",
    "\n",
    "# 빈 인덱스 생성\n",
    "index = GPTVectorStoreIndex.from_documents([])\n",
    "\n",
    "# 문서를 인덱스에 삽입\n",
    "for doc in documents:\n",
    "    index.insert(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9cuUPtE1lRC2"
   },
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "# 문서 로드\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "print(\"documents :\", documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VfNBjpyaXC1N"
   },
   "outputs": [],
   "source": [
    "from llama_index import LLMPredictor, ServiceContext\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# LLMPredictor 준비\n",
    "llm_predictor = LLMPredictor(llm=ChatOpenAI(\n",
    "    temperature=0,  # 온도\n",
    "    model_name=\"gpt-3.5-turbo\" # 모델명\n",
    "))\n",
    "\n",
    "# ServiceContext 준비\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm_predictor=llm_predictor, \n",
    ")\n",
    "\n",
    "# 인덱스 생성\n",
    "index = GPTVectorStoreIndex.from_documents(\n",
    "    documents, \n",
    "    service_context=service_context, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rlrjqvyf0z36"
   },
   "outputs": [],
   "source": [
    "from llama_index import GPTVectorStoreIndex, PromptHelper, ServiceContext\n",
    "\n",
    "# PromptHelper 준비\n",
    "prompt_helper=PromptHelper(\n",
    "    max_input_size=4096, # LLM 입력의 최대 토큰 수\n",
    "    num_output=256, # LLM 출력의 토큰 수\n",
    "    max_chunk_overlap=20, # 청크 오버랩의 최대 토큰 개수\n",
    ")\n",
    "\n",
    "# ServiceContext 준비\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    prompt_helper=prompt_helper\n",
    ")\n",
    "\n",
    "# 인덱스 생성\n",
    "index = GPTVectorStoreIndex.from_documents(\n",
    "    documents, # 문서\n",
    "    service_context=service_context, # ServiceContext\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PE70f8ro9DNH"
   },
   "outputs": [],
   "source": [
    "# sentence_transformers 패키지 설치\n",
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GuD55tAFQH2O"
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from llama_index import GPTVectorStoreIndex, ServiceContext, LangchainEmbedding\n",
    "\n",
    "# 임베딩 모델 준비\n",
    "embed_model = LangchainEmbedding(HuggingFaceEmbeddings(\n",
    "    model_name=\"oshizo/sbert-jsnli-luke-japanese-base-lite\"\n",
    "))\n",
    "\n",
    "# ServiceContext 준비\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n",
    "# 인덱스 생성\n",
    "index = GPTVectorStoreIndex.from_documents(\n",
    "    documents, # 문서\n",
    "    service_context=service_context, # ServiceContext\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fOROANGNSLxS"
   },
   "outputs": [],
   "source": [
    "# 쿼리 엔진 생성\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09NOHlmCpsUQ"
   },
   "outputs": [],
   "source": [
    "# 질의응답\n",
    "response = query_engine.query(\"미코의 소꿉친구 이름은?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gnQm771_sUK0"
   },
   "outputs": [],
   "source": [
    "# 응답\n",
    "print(\"response :\", response.response, \"\\n\")\n",
    "\n",
    "# 소스\n",
    "print(\"source_nodes :\", response.source_nodes, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOFeOShBeDTzLkSHDghkwPw",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
